{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNwop2FEnfRTXGN6lY5igo8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!sudo apt-get -y update\n","!sudo apt-get -y install python3-pip\n","!sudo apt-get -y install python-is-python3\n","!wget https://github.com/PINTO0309/onnx2tf/releases/download/1.7.3/flatc.tar.gz \\\n","  && tar -zxvf flatc.tar.gz \\\n","  && sudo chmod +x flatc \\\n","  && sudo mv flatc /usr/bin/\n","!pip install -U pip \\\n","  && pip install tensorflow==2.13.0 \\\n","  && pip install -U onnx==1.13.1 \\\n","  && python -m pip install onnx_graphsurgeon --index-url https://pypi.ngc.nvidia.com \\\n","  && pip install -U onnxruntime==1.15.0 \\\n","  && pip install -U onnxsim==0.4.33 \\\n","  && pip install -U simple_onnx_processing_tools \\\n","  && pip install -U onnx2tf \\\n","  && pip install -U protobuf==3.20.3 \\\n","  && pip install -U h5py==3.7.0 \\\n","  && pip install -U psutil==5.9.5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CK-PkiaeyErl","executionInfo":{"status":"ok","timestamp":1711977599692,"user_tz":-420,"elapsed":195813,"user":{"displayName":"Việt Hoàng Trần","userId":"05840634668175400410"}},"outputId":"efcd72ee-3b17-4be1-a995-bc82ce1eabb4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,357 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,920 kB]\n","Fetched 3,510 kB in 2s (1,681 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  python3-setuptools python3-wheel\n","Suggested packages:\n","  python-setuptools-doc\n","The following NEW packages will be installed:\n","  python3-pip python3-setuptools python3-wheel\n","0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 1,677 kB of archives.\n","After this operation, 8,967 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.4 [1,305 kB]\n","Fetched 1,677 kB in 1s (1,437 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python3-setuptools.\n","(Reading database ... 121753 files and directories currently installed.)\n","Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n","Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n","Selecting previously unselected package python3-wheel.\n","Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n","Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n","Selecting previously unselected package python3-pip.\n","Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n","Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n","Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n","Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n","Setting up python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  python-is-python3\n","0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 2,788 B of archives.\n","After this operation, 13.3 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 python-is-python3 all 3.9.2-2 [2,788 B]\n","Fetched 2,788 B in 0s (11.8 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python-is-python3.\n","(Reading database ... 122615 files and directories currently installed.)\n","Preparing to unpack .../python-is-python3_3.9.2-2_all.deb ...\n","Unpacking python-is-python3 (3.9.2-2) ...\n","Setting up python-is-python3 (3.9.2-2) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","--2024-04-01 13:17:01--  https://github.com/PINTO0309/onnx2tf/releases/download/1.7.3/flatc.tar.gz\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/541831874/5ec03c45-77e6-4526-acee-0f95d164a30c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T131701Z&X-Amz-Expires=300&X-Amz-Signature=219fbf213fee45e81c3e07a0b4af7157588d1910d1106d7817286ab98ea3dbac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=541831874&response-content-disposition=attachment%3B%20filename%3Dflatc.tar.gz&response-content-type=application%2Foctet-stream [following]\n","--2024-04-01 13:17:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/541831874/5ec03c45-77e6-4526-acee-0f95d164a30c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T131701Z&X-Amz-Expires=300&X-Amz-Signature=219fbf213fee45e81c3e07a0b4af7157588d1910d1106d7817286ab98ea3dbac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=541831874&response-content-disposition=attachment%3B%20filename%3Dflatc.tar.gz&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1387488 (1.3M) [application/octet-stream]\n","Saving to: ‘flatc.tar.gz’\n","\n","flatc.tar.gz        100%[===================>]   1.32M  --.-KB/s    in 0.06s   \n","\n","2024-04-01 13:17:01 (23.6 MB/s) - ‘flatc.tar.gz’ saved [1387488/1387488]\n","\n","flatc\n","Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting pip\n","  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.1.2\n","    Uninstalling pip-23.1.2:\n","      Successfully uninstalled pip-23.1.2\n","Successfully installed pip-24.0\n","Collecting tensorflow==2.13.0\n","  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.3.25)\n","Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n","  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.62.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.9.0)\n","Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n","  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (18.1.1)\n","Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.0)\n","  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n","Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n","  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n","  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.4.0)\n","Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.36.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.0)\n","Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0)\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n","Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.10.0\n","    Uninstalling typing_extensions-4.10.0:\n","      Successfully uninstalled typing_extensions-4.10.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.15.0\n","    Uninstalling tensorflow-estimator-2.15.0:\n","      Successfully uninstalled tensorflow-estimator-2.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.4\n","    Uninstalling gast-0.5.4:\n","      Successfully uninstalled gast-0.5.4\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.0\n","    Uninstalling google-auth-oauthlib-1.2.0:\n","      Successfully uninstalled google-auth-oauthlib-1.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","sqlalchemy 2.0.29 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","pydantic 2.6.4 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n","pydantic-core 2.16.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.13.0 which is incompatible.\n","torch 2.2.1+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting onnx==1.13.1\n","  Downloading onnx-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from onnx==1.13.1) (1.24.3)\n","Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx==1.13.1) (3.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx==1.13.1) (4.5.0)\n","Downloading onnx-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx\n","Successfully installed onnx-1.13.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.ngc.nvidia.com\n","Collecting onnx_graphsurgeon\n","  Downloading https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx_graphsurgeon) (1.24.3)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnx_graphsurgeon) (1.13.1)\n","Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx_graphsurgeon) (3.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx_graphsurgeon) (4.5.0)\n","Installing collected packages: onnx_graphsurgeon\n","Successfully installed onnx_graphsurgeon-0.3.27\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting onnxruntime==1.15.0\n","  Downloading onnxruntime-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n","Collecting coloredlogs (from onnxruntime==1.15.0)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.0) (24.3.25)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.0) (1.24.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.0) (24.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.0) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.0) (1.12)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.15.0)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.15.0) (1.3.0)\n","Downloading onnxruntime-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.15.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting onnxsim==0.4.33\n","  Downloading onnxsim-0.4.33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxsim==0.4.33) (1.13.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnxsim==0.4.33) (13.7.1)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxsim==0.4.33) (1.24.3)\n","Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxsim==0.4.33) (3.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxsim==0.4.33) (4.5.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim==0.4.33) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim==0.4.33) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim==0.4.33) (0.1.2)\n","Downloading onnxsim-0.4.33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnxsim\n","Successfully installed onnxsim-0.4.33\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting simple_onnx_processing_tools\n","  Downloading simple_onnx_processing_tools-1.1.30-py3-none-any.whl.metadata (21 kB)\n","Collecting snc4onnx>=1.0.12 (from simple_onnx_processing_tools)\n","  Downloading snc4onnx-1.0.12-py3-none-any.whl.metadata (11 kB)\n","Collecting sne4onnx>=1.0.11 (from simple_onnx_processing_tools)\n","  Downloading sne4onnx-1.0.11-py3-none-any.whl.metadata (7.0 kB)\n","Collecting snd4onnx>=1.1.6 (from simple_onnx_processing_tools)\n","  Downloading snd4onnx-1.1.6-py3-none-any.whl.metadata (6.0 kB)\n","Collecting scs4onnx>=1.0.18 (from simple_onnx_processing_tools)\n","  Downloading scs4onnx-1.0.18-py3-none-any.whl.metadata (12 kB)\n","Collecting sog4onnx>=1.0.16 (from simple_onnx_processing_tools)\n","  Downloading sog4onnx-1.0.16-py3-none-any.whl.metadata (11 kB)\n","Collecting sam4onnx>=1.0.14 (from simple_onnx_processing_tools)\n","  Downloading sam4onnx-1.0.14-py3-none-any.whl.metadata (10 kB)\n","Collecting soc4onnx>=1.0.2 (from simple_onnx_processing_tools)\n","  Downloading soc4onnx-1.0.2-py3-none-any.whl.metadata (4.2 kB)\n","Collecting scc4onnx>=1.0.5 (from simple_onnx_processing_tools)\n","  Downloading scc4onnx-1.0.5-py3-none-any.whl.metadata (9.6 kB)\n","Collecting sna4onnx>=1.0.6 (from simple_onnx_processing_tools)\n","  Downloading sna4onnx-1.0.6-py3-none-any.whl.metadata (13 kB)\n","Collecting sbi4onnx>=1.0.5 (from simple_onnx_processing_tools)\n","  Downloading sbi4onnx-1.0.5-py3-none-any.whl.metadata (6.5 kB)\n","Collecting sor4onnx>=1.0.5 (from simple_onnx_processing_tools)\n","  Downloading sor4onnx-1.0.5-py3-none-any.whl.metadata (6.5 kB)\n","Collecting sit4onnx>=1.0.7 (from simple_onnx_processing_tools)\n","  Downloading sit4onnx-1.0.8-py3-none-any.whl.metadata (15 kB)\n","Collecting onnx2json>=2.0.4 (from simple_onnx_processing_tools)\n","  Downloading onnx2json-2.0.4-py3-none-any.whl.metadata (3.5 kB)\n","Collecting json2onnx>=2.0.3 (from simple_onnx_processing_tools)\n","  Downloading json2onnx-2.0.3-py3-none-any.whl.metadata (3.3 kB)\n","Collecting sed4onnx>=1.0.5 (from simple_onnx_processing_tools)\n","  Downloading sed4onnx-1.0.5-py3-none-any.whl.metadata (4.9 kB)\n","Collecting soa4onnx>=1.0.4 (from simple_onnx_processing_tools)\n","  Downloading soa4onnx-1.0.4-py3-none-any.whl.metadata (5.7 kB)\n","Collecting sod4onnx>=1.0.0 (from simple_onnx_processing_tools)\n","  Downloading sod4onnx-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n","Collecting ssi4onnx>=1.0.2 (from simple_onnx_processing_tools)\n","  Downloading ssi4onnx-1.0.2-py3-none-any.whl.metadata (4.2 kB)\n","Collecting ssc4onnx>=1.0.5 (from simple_onnx_processing_tools)\n","  Downloading ssc4onnx-1.0.8-py3-none-any.whl.metadata (3.8 kB)\n","Collecting sio4onnx>=1.0.2 (from simple_onnx_processing_tools)\n","  Downloading sio4onnx-1.0.2-py3-none-any.whl.metadata (7.5 kB)\n","Collecting svs4onnx>=1.0.0 (from simple_onnx_processing_tools)\n","  Downloading svs4onnx-1.0.0-py3-none-any.whl.metadata (5.9 kB)\n","Collecting onnx2tf>=1.17.6 (from simple_onnx_processing_tools)\n","  Downloading onnx2tf-1.19.12-py3-none-any.whl.metadata (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sng4onnx>=1.0.1 (from simple_onnx_processing_tools)\n","  Downloading sng4onnx-1.0.1-py3-none-any.whl.metadata (4.6 kB)\n","Collecting sde4onnx>=1.0.0 (from simple_onnx_processing_tools)\n","  Downloading sde4onnx-1.0.0-py3-none-any.whl.metadata (4.3 kB)\n","Collecting spo4onnx>=1.0.3 (from simple_onnx_processing_tools)\n","  Downloading spo4onnx-1.0.3-py3-none-any.whl.metadata (8.9 kB)\n","Downloading simple_onnx_processing_tools-1.1.30-py3-none-any.whl (7.8 kB)\n","Downloading json2onnx-2.0.3-py3-none-any.whl (5.0 kB)\n","Downloading onnx2json-2.0.4-py3-none-any.whl (5.0 kB)\n","Downloading onnx2tf-1.19.12-py3-none-any.whl (412 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sam4onnx-1.0.14-py3-none-any.whl (10 kB)\n","Downloading sbi4onnx-1.0.5-py3-none-any.whl (6.8 kB)\n","Downloading scc4onnx-1.0.5-py3-none-any.whl (9.4 kB)\n","Downloading scs4onnx-1.0.18-py3-none-any.whl (10 kB)\n","Downloading sde4onnx-1.0.0-py3-none-any.whl (5.5 kB)\n","Downloading sed4onnx-1.0.5-py3-none-any.whl (5.7 kB)\n","Downloading sio4onnx-1.0.2-py3-none-any.whl (6.9 kB)\n","Downloading sit4onnx-1.0.8-py3-none-any.whl (11 kB)\n","Downloading sna4onnx-1.0.6-py3-none-any.whl (10 kB)\n","Downloading snc4onnx-1.0.12-py3-none-any.whl (10 kB)\n","Downloading snd4onnx-1.1.6-py3-none-any.whl (9.0 kB)\n","Downloading sne4onnx-1.0.11-py3-none-any.whl (7.0 kB)\n","Downloading sng4onnx-1.0.1-py3-none-any.whl (5.8 kB)\n","Downloading soa4onnx-1.0.4-py3-none-any.whl (6.3 kB)\n","Downloading soc4onnx-1.0.2-py3-none-any.whl (5.7 kB)\n","Downloading sod4onnx-1.0.0-py3-none-any.whl (5.9 kB)\n","Downloading sog4onnx-1.0.16-py3-none-any.whl (9.6 kB)\n","Downloading sor4onnx-1.0.5-py3-none-any.whl (7.1 kB)\n","Downloading spo4onnx-1.0.3-py3-none-any.whl (11 kB)\n","Downloading ssc4onnx-1.0.8-py3-none-any.whl (6.6 kB)\n","Downloading ssi4onnx-1.0.2-py3-none-any.whl (5.5 kB)\n","Downloading svs4onnx-1.0.0-py3-none-any.whl (6.3 kB)\n","Installing collected packages: svs4onnx, ssi4onnx, ssc4onnx, spo4onnx, sor4onnx, sog4onnx, sod4onnx, soc4onnx, soa4onnx, sng4onnx, sne4onnx, snd4onnx, snc4onnx, sit4onnx, sio4onnx, sed4onnx, sde4onnx, scs4onnx, scc4onnx, sbi4onnx, sam4onnx, onnx2tf, onnx2json, json2onnx, sna4onnx, simple_onnx_processing_tools\n","Successfully installed json2onnx-2.0.3 onnx2json-2.0.4 onnx2tf-1.19.12 sam4onnx-1.0.14 sbi4onnx-1.0.5 scc4onnx-1.0.5 scs4onnx-1.0.18 sde4onnx-1.0.0 sed4onnx-1.0.5 simple_onnx_processing_tools-1.1.30 sio4onnx-1.0.2 sit4onnx-1.0.8 sna4onnx-1.0.6 snc4onnx-1.0.12 snd4onnx-1.1.6 sne4onnx-1.0.11 sng4onnx-1.0.1 soa4onnx-1.0.4 soc4onnx-1.0.2 sod4onnx-1.0.0 sog4onnx-1.0.16 sor4onnx-1.0.5 spo4onnx-1.0.3 ssc4onnx-1.0.8 ssi4onnx-1.0.2 svs4onnx-1.0.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: onnx2tf in /usr/local/lib/python3.10/dist-packages (1.19.12)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting h5py==3.7.0\n","  Downloading h5py-3.7.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py==3.7.0) (1.24.3)\n","Downloading h5py-3.7.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: h5py\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.9.0\n","    Uninstalling h5py-3.9.0:\n","      Successfully uninstalled h5py-3.9.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.13.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h5py-3.7.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: psutil==5.9.5 in /usr/local/lib/python3.10/dist-packages (5.9.5)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"6db6fc43565840cf8294f488b243ec0e"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install -U onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"feS92nfN3_dY","executionInfo":{"status":"ok","timestamp":1711978816829,"user_tz":-420,"elapsed":12856,"user":{"displayName":"Việt Hoàng Trần","userId":"05840634668175400410"}},"outputId":"19be3310-93b5-44cc-fd54-958b0951568b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Collecting onnx\n","  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.24.3)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx\n","  Attempting uninstall: onnx\n","    Found existing installation: onnx 1.13.1\n","    Uninstalling onnx-1.13.1:\n","      Successfully uninstalled onnx-1.13.1\n","Successfully installed onnx-1.16.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["onnx"]},"id":"12a67d5f8b444457a17589677cfd3f7f"}},"metadata":{}}]},{"cell_type":"code","source":["!git clone https://github.com/hoangtv2000/Notes.git\n","%cd Notes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElmF1khkyrkX","executionInfo":{"status":"ok","timestamp":1711977632698,"user_tz":-420,"elapsed":399,"user":{"displayName":"Việt Hoàng Trần","userId":"05840634668175400410"}},"outputId":"38d709d4-898b-42cc-c6aa-4301faaf0332"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'Notes' already exists and is not an empty directory.\n","/content/Notes\n"]}]},{"cell_type":"code","source":["import onnx2tf\n","\n","data = [[\"images\", \"/content/Notes/data.npy\", [[[[0, 0, 0]]]], [[[[255, 255, 255]]]]]]\n","\n","onnx2tf.convert(\n","    input_onnx_file_path=\"/content/Notes/model_uint8_sparseml.onnx\",\n","    copy_onnx_input_output_names_to_tflite=True,\n","    input_output_quant_dtype=\"int8\",\n","    output_integer_quantized_tflite=True,\n","    output_folder_path=\"model.tf\",\n","    non_verbose=False,\n","    quant_type=\"per-tensor\",\n","    overwrite_input_shape=['images:1,3,640,640'],\n","    keep_nwc_or_nhwc_or_ndhwc_input_names=[\"images\"],\n","    batch_size=1,\n","    not_use_onnxsim=True,\n","    custom_input_op_name_np_data_path=data,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"kPLQ94rGznST","executionInfo":{"status":"error","timestamp":1711984010367,"user_tz":-420,"elapsed":16947,"user":{"displayName":"Việt Hoàng Trần","userId":"05840634668175400410"}},"outputId":"7f6ce08a-a3f8-4ab0-aedb-617b949ab620"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n","\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n","\n","\u001b[07mModel loaded\u001b[0m ========================================================================\n","\n","\u001b[07mModel conversion started\u001b[0m ============================================================\n","\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: images \u001b[32mshape\u001b[0m: [1, 3, 640, 640] \u001b[32mdtype\u001b[0m: uint8\n","\u001b[33mWARNING:\u001b[0m The optimization process for shape estimation is skipped because it contains OPs that cannot be inferred by the standard onnxruntime.\n","\u001b[33mWARNING:\u001b[0m [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: /onnxruntime_src/onnxruntime/core/graph/model.cc:149 onnxruntime::Model::Model(onnx::ModelProto&&, const PathString&, const IOnnxRuntimeOpSchemaRegistryList*, const onnxruntime::logging::Logger&, const onnxruntime::ModelOptions&) Unsupported model IR version: 10, max supported IR version: 9\n","\n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m2 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.0/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: images \u001b[36mshape\u001b[0m: [1, 3, 640, 640] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.0/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [16, 3, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3456 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.0/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_5/Pad:0 \u001b[34mshape\u001b[0m: (1, 642, 642, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 3, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_27/convolution:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m3 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.0/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.0/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.0/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 16, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.0/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_27/convolution:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m4 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.0/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.0/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.0/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m5 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.0/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.0/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.0/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.0/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_190/Mul:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m6 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.0/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.0/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.0.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3464 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.0/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m7 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.0/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.0/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.0.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3464 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.0/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_191/Mul:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m8 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.0/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.0/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.0/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_191/Mul:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_27/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m9 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.0/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.0/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.0/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.0/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_191/Mul:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_27/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_194/Mul:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m10 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.1/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.0/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3456 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 320, 320, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m11 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 320, 320] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [28, 16, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3456 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_6/Pad:0 \u001b[34mshape\u001b[0m: (1, 322, 322, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 16, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_28/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m12 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 28, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_28/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_98/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m13 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_98/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m14 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_196/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m15 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m16 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_197/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m17 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_197/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_28/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m18 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_197/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_28/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_200/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m19 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv1/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3456 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m20 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 28, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [32, 28, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3456 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_73/Sub:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_29/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m21 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_29/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_101/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m22 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_101/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m23 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_202/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m24 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3482 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m25 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3482 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_203/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m26 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_203/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_29/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m27 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_203/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_29/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_206/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m28 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Slice\u001b[35m onnx_op_name\u001b[0m: wa/model.2/Slice_1\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.22/dfl/Constant_3_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.2/Constant_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: strided_slice\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_206/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.begin\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.end\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_8/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m29 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Slice\u001b[35m onnx_op_name\u001b[0m: wa/model.2/Slice\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.22/dfl/Constant_3_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.2/Constant_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/Slice_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: strided_slice\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_206/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.begin\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.end\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_9/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m30 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/add_input_0/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.m.0.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m31 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/add_input_0/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.m.0.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_207/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m32 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [11, 16, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_76/Sub:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 16, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_30/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m33 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 11, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_30/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_104/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m34 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_104/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m35 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/m.0/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_209/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m36 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.m.0.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3492 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m37 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.m.0.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3492 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_210/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m38 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_210/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_30/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m39 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/m.0/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_210/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_30/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_213/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m40 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.m.0.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m41 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 11, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [16, 11, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_78/Sub:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 11, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_31/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m42 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 16, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_31/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_107/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m43 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_107/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m44 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/m.0/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_215/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m45 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.m.0.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3501 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m46 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.m.0.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3501 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_216/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m47 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_216/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_31/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m48 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/m.0/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_216/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_31/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_219/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m49 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/add_input_1/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.m.0.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m50 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/add_input_1/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.m.0.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_220/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m51 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.2/m.0/Add\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/m.0/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/m.0/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_207/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_220/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_110/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m52 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: wa/model.2/Concat\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/Slice_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.2/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 16, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 48, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_9/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_8/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_110/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_5/concat:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m53 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 48, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 48, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m54 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 48, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [32, 48, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_81/Sub:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_32/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m55 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_32/convolution:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_112/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m56 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_112/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m57 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_224/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m58 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3511 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m59 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.2.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3511 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_225/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m60 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_225/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_32/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m61 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.2/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.2/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_225/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_32/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_228/Mul:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m62 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.3/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.2/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.3.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.3/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m63 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.3/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.3/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 160, 160] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.3/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [34, 32, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.3/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_7/Pad:0 \u001b[34mshape\u001b[0m: (1, 162, 162, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_33/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m64 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.3/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.3/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.3/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 34, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.3/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_33/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_115/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m65 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.3/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.3/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.3/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_115/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m66 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.3/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.3/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.3/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.3/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_230/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m67 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.3/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.3/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.3.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3520 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.3/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m68 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.3/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.3/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.3.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3520 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.3/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_231/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m69 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.3/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.3/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.3/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_231/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_33/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m70 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.3/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.3/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.3/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.3/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_231/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_33/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_234/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m71 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv1/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.3/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3521 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m72 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [64, 34, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3521 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_85/Sub:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 34, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_34/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m73 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 64, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_34/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_118/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m74 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_118/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m75 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_236/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m76 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3529 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m77 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3529 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_237/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m78 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_237/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_34/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m79 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_237/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_34/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_240/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m80 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Slice\u001b[35m onnx_op_name\u001b[0m: wa/model.4/Slice_1\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.22/Constant_9_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.2/Constant_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: strided_slice\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_240/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.begin\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.end\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_10/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m81 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Slice\u001b[35m onnx_op_name\u001b[0m: wa/model.4/Slice\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.2/Constant_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/Slice_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: strided_slice\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_240/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.begin\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.end\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_11/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m82 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/add_input_0/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.0.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m83 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/add_input_0/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.0.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_241/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m84 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [16, 32, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_88/Sub:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_35/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m85 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 16, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_35/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_121/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m86 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_121/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m87 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.0/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_243/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m88 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.0.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3539 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m89 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.0.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3539 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_244/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m90 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_244/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_35/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m91 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.0/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_244/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_35/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_247/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m92 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.0.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3540 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m93 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 16, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [32, 16, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3540 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_90/Sub:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 16, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_36/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m94 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_36/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_124/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m95 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_124/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m96 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.0/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_249/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m97 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.0.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m98 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.0.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_250/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m99 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_250/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_36/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m100 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.0/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_250/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_36/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_253/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m101 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/add_input_1/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.0.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m102 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/add_input_1/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.0.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_254/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m103 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.0/Add\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.0/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_241/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_254/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_127/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m104 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/add_input_0/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.1.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3521 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m105 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/add_input_0/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.1.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3521 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_257/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m106 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [12, 32, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3521 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_94/Sub:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_37/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m107 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 12, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_37/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_129/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m108 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_129/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m109 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.1/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_259/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m110 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.1.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3559 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m111 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.1.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3559 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_260/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m112 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_260/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_37/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m113 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.1/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_260/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_37/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_263/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m114 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.1.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3540 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m115 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 12, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [32, 12, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3540 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_96/Sub:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 12) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 12, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_38/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m116 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_38/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_132/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m117 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_132/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m118 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.1/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_265/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m119 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.1.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3568 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m120 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.1.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3568 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_266/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m121 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_266/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_38/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m122 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.1/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_266/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_38/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_269/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m123 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/add_input_1/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.1.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m124 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/add_input_1/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.m.1.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_270/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m125 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.4/m.1/Add\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/m.1/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/m.1/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/m.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_257/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_270/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_135/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m126 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: wa/model.4/Concat\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/Slice_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.4/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.4/m.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_11/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_10/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_127/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.input3\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_135/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_6/concat:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m127 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m128 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [64, 128, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_99/Sub:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_39/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m129 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 64, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_39/convolution:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_137/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m130 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_137/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m131 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_274/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m132 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3578 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m133 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.4.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3578 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_275/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m134 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_275/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_39/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m135 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.4/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.4/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.4/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_275/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_39/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_278/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m136 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.5/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.4/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.5.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.5/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m137 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.5/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.5/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.5/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [81, 64, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.5/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_8/Pad:0 \u001b[34mshape\u001b[0m: (1, 82, 82, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_40/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m138 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.5/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.5/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.5/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 81, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.5/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_40/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_140/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m139 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.5/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.5/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.5/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_140/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m140 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.5/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.5/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.5/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.5/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_280/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m141 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.5/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.5/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.5.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3587 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.5/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m142 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.5/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.5/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.5.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3587 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.5/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_281/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m143 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.5/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.5/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.5/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_281/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_40/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m144 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.5/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.5/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.5/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.5/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_281/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_40/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_284/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m145 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv1/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.5/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m146 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 81, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [128, 81, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_103/Sub:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 81) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 81, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_41/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m147 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 128, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_41/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_143/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m148 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_143/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m149 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_286/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m150 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3596 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m151 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3596 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_287/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m152 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_287/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_41/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m153 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_287/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_41/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_290/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m154 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Slice\u001b[35m onnx_op_name\u001b[0m: wa/model.6/Slice_1\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.22/Constant_9_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.6/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.2/Constant_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: strided_slice\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_290/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.begin\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.end\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_12/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m155 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Slice\u001b[35m onnx_op_name\u001b[0m: wa/model.6/Slice\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.22/Constant_9_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.2/Constant_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/Slice_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: strided_slice\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_290/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.begin\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.end\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_13/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m156 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/add_input_0/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.0.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m157 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/add_input_0/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.0.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_291/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m158 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [34, 64, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_106/Sub:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_42/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m159 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 34, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_42/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_146/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m160 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_146/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m161 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.0/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_293/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m162 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.0.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3606 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m163 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.0.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3606 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_294/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m164 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_294/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_42/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m165 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.0/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_294/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_42/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_297/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m166 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.0.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m167 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 34, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [64, 34, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_108/Sub:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 34) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 34, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_43/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m168 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 64, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_43/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_149/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m169 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_149/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m170 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.0/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_299/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m171 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.0.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3596 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m172 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.0.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3596 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_300/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m173 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_300/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_43/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m174 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.0/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_300/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_43/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_303/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m175 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/add_input_1/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.0.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m176 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/add_input_1/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.0.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_304/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m177 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.0/Add\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.0/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_291/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_304/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_152/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m178 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/add_input_0/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.1.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m179 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/add_input_0/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.1.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_307/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m180 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [33, 64, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_112/Sub:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_44/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m181 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 33, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_44/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_154/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m182 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_154/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m183 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.1/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_309/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m184 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.1.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3626 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m185 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.1.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3626 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_310/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m186 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_310/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_44/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m187 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.1/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_310/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_44/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_313/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m188 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.1.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m189 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 33, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [64, 33, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_114/Sub:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 33) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 33, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_45/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m190 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 64, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_45/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_157/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m191 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_157/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m192 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.1/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_315/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m193 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.1.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3635 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m194 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.1.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3635 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_316/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m195 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_316/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_45/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m196 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.1/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_316/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_45/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_319/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m197 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/add_input_1/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.1.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m198 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/add_input_1/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.m.1.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_320/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m199 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.6/m.1/Add\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/m.1/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/m.1/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/m.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_307/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_320/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_160/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m200 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: wa/model.6/Concat\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/Slice_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.6/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.6/m.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 256, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_13/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_12/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_152/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.input3\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_160/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_7/concat:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m201 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 256, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 256, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m202 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 256, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [92, 256, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3530 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_117/Sub:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_46/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m203 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 92, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_46/convolution:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_162/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m204 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_162/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m205 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_324/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m206 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3626 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m207 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.6.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3626 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_325/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m208 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_325/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_46/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m209 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.6/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.6/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_325/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_46/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_328/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m210 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.7/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.6/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.7.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.7/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m211 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.7/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.7/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 92, 40, 40] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.7/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [226, 92, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.7/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_9/Pad:0 \u001b[34mshape\u001b[0m: (1, 42, 42, 92) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 92, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_47/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m212 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.7/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.7/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.7/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 226, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.7/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_47/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_165/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m213 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.7/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.7/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.7/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_165/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m214 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.7/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.7/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.7/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.7/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_330/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m215 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.7/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.7/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.7.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3568 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.7/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m216 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.7/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.7/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.7.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3568 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.7/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_331/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m217 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.7/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.7/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.7/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_331/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_47/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m218 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.7/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.7/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.7/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.7/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_331/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_47/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_334/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m219 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv1/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.7/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m220 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 226, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [256, 226, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_121/Sub:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 226) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 226, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_48/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m221 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 256, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_48/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_168/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m222 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_168/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m223 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_336/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m224 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3663 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m225 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3663 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_337/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m226 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_337/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_48/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m227 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_337/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_48/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_340/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m228 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Slice\u001b[35m onnx_op_name\u001b[0m: wa/model.8/Slice_1\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.6/Mul_1_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.8/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.2/Constant_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: strided_slice\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_340/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.begin\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.end\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_14/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m229 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Slice\u001b[35m onnx_op_name\u001b[0m: wa/model.8/Slice\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 256, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.6/Mul_1_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.2/Constant_output_0 \u001b[36mshape\u001b[0m: (1,) \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/Slice_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: strided_slice\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_340/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.begin\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.end\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: int64 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_15/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m230 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/add_input_0/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.m.0.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m231 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/add_input_0/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.m.0.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_341/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m232 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/add_input_0/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [124, 128, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_124/Sub:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_49/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m233 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 124, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_49/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_171/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m234 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_171/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m235 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/m.0/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_343/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m236 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.m.0.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3673 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m237 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.m.0.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3673 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_344/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m238 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_344/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_49/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m239 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/m.0/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_344/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_49/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_347/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m240 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.m.0.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m241 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 124, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [128, 124, 3, 3] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_126/Sub:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 124) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 124, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_50/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m242 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 128, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_50/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_174/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m243 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_174/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m244 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/m.0/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_349/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m245 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.m.0.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3596 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m246 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.m.0.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3596 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_350/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m247 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_350/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_50/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m248 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/m.0/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_350/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_50/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_353/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m249 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/add_input_1/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.m.0.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m250 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/add_input_1/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/add_input_1/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.m.0.add_input_1.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_354/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m251 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.8/m.0/Add\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/m.0/add_input_0/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/m.0/add_input_1/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_341/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_354/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_177/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m252 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: wa/model.8/Concat\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/Slice_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/Slice_1_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.8/m.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_15/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice_14/StridedSlice:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_177/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_8/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m253 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m254 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [84, 384, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_129/Sub:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 384, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_51/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m255 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 84, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_51/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_179/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m256 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_179/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m257 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_358/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m258 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3692 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m259 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.8.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3692 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_359/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m260 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_359/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_51/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m261 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.8/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.8/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.8/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_359/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_51/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_362/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m262 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv1/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.8/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.cv1.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m263 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv1/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 84, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.9/cv1/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [58, 84, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_131/Sub:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 84) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 84, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_52/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m264 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv1/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.9/cv1/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 58, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_52/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_182/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m265 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv1/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_182/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m266 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv1/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.9/cv1/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_364/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m267 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv1/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3701 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m268 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv1/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.cv1.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3701 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_365/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m269 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv1/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_365/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_52/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m270 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv1/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.9/cv1/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_365/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_52/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_368/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m271 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/m/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.m.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/m/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m272 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/m/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/m/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.m.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/m/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_369/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m273 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: wa/model.9/m/module/MaxPool\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/m/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/m/module/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pool_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_369/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [5, 5] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [2, 2, 2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_3/max_pool:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m274 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/m/activation_post_process_1/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/m/module/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.m.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/m/activation_post_process_1/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m275 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/m/activation_post_process_1/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/m/activation_post_process_1/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.m.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/m/activation_post_process_1/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_370/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m276 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: wa/model.9/m/module_1/MaxPool\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/m/activation_post_process_1/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/m/module_1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pool_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_370/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [5, 5] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [2, 2, 2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_4/max_pool:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m277 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/m/activation_post_process_2/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/m/module_1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.m.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/m/activation_post_process_2/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m278 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/m/activation_post_process_2/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/m/activation_post_process_2/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.m.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3493 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/m/activation_post_process_2/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_371/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m279 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: wa/model.9/m/module_2/MaxPool\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/m/activation_post_process_2/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/m/module_2/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pool_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_371/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [5, 5] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [2, 2, 2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_5/max_pool:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m280 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: wa/model.9/Concat\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv1/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.9/m/module/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.9/m/module_1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/model.9/m/module_2/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 58, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 232, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_368/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_3/max_pool:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_4/max_pool:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.input3\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_5/max_pool:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 58) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_9/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 232) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m281 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv2/conv/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 232, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.cv2.conv.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 232, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 232) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 232) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m282 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvInteger\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv2/conv/module/Conv_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv2/conv/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 232, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.9/cv2/conv/module/Conv.weight_quantized \u001b[36mshape\u001b[0m: [130, 232, 1, 1] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3483 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::QuantizeLinear_3462 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_136/Sub:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 232) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 232, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_53/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m283 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv2/conv/module/Conv_bias_add_quant\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv2/conv/module/bn/BatchNormalization_output_0_quant \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.9/cv2/conv/module/Conv_bias_add.bias_quantized \u001b[36mshape\u001b[0m: [1, 130, 1, 1] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_53/convolution:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_188/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m284 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Cast\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv2/conv/module/Conv_bias_add_quant_cast\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv2/conv/module/Conv_bias_add_quant_output \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: int32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: cast\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_188/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.dtype\u001b[0m: \u001b[34mname\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m285 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv2/conv/module/Conv_bias_add_quant_rescale_mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv2/conv/module/Conv_bias_add_quant_output_cast \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.9/cv2/conv/module/Conv_bias_add.bias_quantized.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_373/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m286 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: QuantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv2/act/activation_post_process/QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv2/conv/module/bn/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3713 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: QuantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.y_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m287 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: DequantizeLinear\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv2/act/activation_post_process/DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv2/act/activation_post_process/QuantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.9.cv2.act.quant.activation_post_process.scale \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::QuantizeLinear_3713 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: uint8\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: DequantizeLinear\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.x_scale\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.x_zero_point\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_374/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m288 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv2/act/module/Sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_374/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_53/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m289 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/model.9/cv2/act/module/Mul\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv2/act/activation_post_process/DequantizeLinear_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/model.9/cv2/act/module/Sigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.9/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_374/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_53/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_377/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 130) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m290 / 643\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: wa/model.10/Resize\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/model.9/cv2/act/module/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 130, 20, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/model.10/Constant_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/model.10/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 130, 40, 40] \u001b[36mdtype\u001b[0m: float32\n","\u001b[31mERROR:\u001b[0m The trace log is below.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\", line 310, in print_wrapper_func\n","    result = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\", line 383, in inverted_operation_enable_disable_wrapper_func\n","    result = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\", line 53, in get_replacement_parameter_wrapper_func\n","    func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/ops/Resize.py\", line 417, in make_node\n","    resized_tensor = Lambda(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1045, in __call__\n","    outputs = call_fn(inputs, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/layers/core.py\", line 913, in call\n","    result = self.function(inputs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\", line 1142, in upsampling2d_nearest\n","    return tf.compat.v1.image.resize_nearest_neighbor(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/image_ops_impl.py\", line 4769, in resize_nearest_neighbor\n","    return gen_image_ops.resize_nearest_neighbor(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 3858, in resize_nearest_neighbor\n","    return resize_nearest_neighbor_eager_fallback(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 3896, in resize_nearest_neighbor_eager_fallback\n","    _attr_T, (images,) = _execute.args_to_matching_eager([images], ctx, [_dtypes.int8, _dtypes.uint8, _dtypes.int16, _dtypes.uint16, _dtypes.int32, _dtypes.int64, _dtypes.half, _dtypes.float32, _dtypes.float64, _dtypes.bfloat16, ])\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 251, in args_to_matching_eager\n","    tensor = tensor_conversion_registry.convert(t)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n","    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 324, in _constant_tensor_conversion_function\n","    return constant(v, dtype=dtype, name=name)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 263, in constant\n","    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\n","    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 285, in _constant_eager_impl\n","    t = convert_to_eager_tensor(value, ctx, dtype)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 98, in convert_to_eager_tensor\n","    return ops.EagerTensor(value, ctx.device_name, dtype)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/keras_tensor.py\", line 285, in __array__\n","    raise TypeError(\n","TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(1, 20, 20, 130), dtype=tf.float32, name=None), name='tf.math.multiply_377/Mul:0', description=\"created by layer 'tf.math.multiply_377'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n","\n","\u001b[31mERROR:\u001b[0m input_onnx_file_path: /content/Notes/model_uint8_sparseml.onnx\n","\u001b[31mERROR:\u001b[0m onnx_op_name: wa/model.10/Resize\n","\u001b[31mERROR:\u001b[0m Read this and deal with it. https://github.com/PINTO0309/onnx2tf#parameter-replacement\n","\u001b[31mERROR:\u001b[0m Alternatively, if the input OP has a dynamic dimension, use the -b or -ois option to rewrite it to a static shape and try again.\n","\u001b[31mERROR:\u001b[0m If the input OP of ONNX before conversion is NHWC or an irregular channel arrangement other than NCHW, use the -kt or -kat option.\n","\u001b[31mERROR:\u001b[0m Also, for models that include NonMaxSuppression in the post-processing, try the -onwdt option.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\", line 310, in print_wrapper_func\n","    result = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\", line 383, in inverted_operation_enable_disable_wrapper_func\n","    result = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\", line 53, in get_replacement_parameter_wrapper_func\n","    func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/ops/Resize.py\", line 417, in make_node\n","    resized_tensor = Lambda(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1045, in __call__\n","    outputs = call_fn(inputs, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/layers/core.py\", line 913, in call\n","    result = self.function(inputs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\", line 1142, in upsampling2d_nearest\n","    return tf.compat.v1.image.resize_nearest_neighbor(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/image_ops_impl.py\", line 4769, in resize_nearest_neighbor\n","    return gen_image_ops.resize_nearest_neighbor(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 3858, in resize_nearest_neighbor\n","    return resize_nearest_neighbor_eager_fallback(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 3896, in resize_nearest_neighbor_eager_fallback\n","    _attr_T, (images,) = _execute.args_to_matching_eager([images], ctx, [_dtypes.int8, _dtypes.uint8, _dtypes.int16, _dtypes.uint16, _dtypes.int32, _dtypes.int64, _dtypes.half, _dtypes.float32, _dtypes.float64, _dtypes.bfloat16, ])\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 251, in args_to_matching_eager\n","    tensor = tensor_conversion_registry.convert(t)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n","    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 324, in _constant_tensor_conversion_function\n","    return constant(v, dtype=dtype, name=name)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 263, in constant\n","    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\n","    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 285, in _constant_eager_impl\n","    t = convert_to_eager_tensor(value, ctx, dtype)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 98, in convert_to_eager_tensor\n","    return ops.EagerTensor(value, ctx.device_name, dtype)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/keras_tensor.py\", line 285, in __array__\n","    raise TypeError(\n","TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(1, 20, 20, 130), dtype=tf.float32, name=None), name='tf.math.multiply_377/Mul:0', description=\"created by layer 'tf.math.multiply_377'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-2-872f7a7975db>\", line 5, in <cell line: 5>\n","    onnx2tf.convert(\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/onnx2tf.py\", line 1019, in convert\n","    op.make_node(\n","  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\", line 376, in print_wrapper_func\n","    sys.exit(1)\n","SystemExit: 1\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","AttributeError: 'tuple' object has no attribute 'tb_frame'\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\u001b[0m in \u001b[0;36mprint_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\u001b[0m in \u001b[0;36minverted_operation_enable_disable_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverted_operation_enable_disable_wrapper_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \"\"\"\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\u001b[0m in \u001b[0;36mget_replacement_parameter_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             ]\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_replacement_parameter_wrapper_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx2tf/ops/Resize.py\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(graph_node, tf_layers_dict, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mhalf_pixel_centers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         resized_tensor = Lambda(\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mtf_resize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1045\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\u001b[0m in \u001b[0;36mupsampling2d_nearest\u001b[0;34m(input_tensor, new_size, align_corners, half_pixel_centers, name)\u001b[0m\n\u001b[1;32m   1141\u001b[0m ):\n\u001b[0;32m-> 1142\u001b[0;31m     return tf.compat.v1.image.resize_nearest_neighbor(\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_nearest_neighbor\u001b[0;34m(images, size, align_corners, name, half_pixel_centers)\u001b[0m\n\u001b[1;32m   4768\u001b[0m                             half_pixel_centers=False):\n\u001b[0;32m-> 4769\u001b[0;31m   return gen_image_ops.resize_nearest_neighbor(\n\u001b[0m\u001b[1;32m   4770\u001b[0m       \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mresize_nearest_neighbor\u001b[0;34m(images, size, align_corners, half_pixel_centers, name)\u001b[0m\n\u001b[1;32m   3857\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3858\u001b[0;31m       return resize_nearest_neighbor_eager_fallback(\n\u001b[0m\u001b[1;32m   3859\u001b[0m           \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_corners\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mresize_nearest_neighbor_eager_fallback\u001b[0;34m(images, size, align_corners, half_pixel_centers, name, ctx)\u001b[0m\n\u001b[1;32m   3895\u001b[0m   \u001b[0mhalf_pixel_centers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhalf_pixel_centers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"half_pixel_centers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3896\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3897\u001b[0m   \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    250\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    323\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[0;32m--> 263\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    264\u001b[0m                         allow_broadcast=True)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0;34mf\"You are passing {self}, an intermediate Keras symbolic \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(1, 20, 20, 130), dtype=tf.float32, name=None), name='tf.math.multiply_377/Mul:0', description=\"created by layer 'tf.math.multiply_377'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-2-872f7a7975db>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m onnx2tf.convert(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0minput_onnx_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/Notes/model_uint8_sparseml.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx2tf/onnx2tf.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_integer_quantized_tflite, quant_type, custom_input_op_name_np_data_path, input_output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, no_large_tensor, output_nms_with_dynamic_tensor, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indicies_is_int64, replace_argmax_to_reducemax_and_indicies_is_float32, replace_argmax_to_fused_argmax_and_indicies_is_int64, replace_argmax_to_fused_argmax_and_indicies_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elem...\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             op.make_node(\n\u001b[0m\u001b[1;32m   1020\u001b[0m                 \u001b[0mgraph_node\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_node\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx2tf/utils/common_functions.py\u001b[0m in \u001b[0;36mprint_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m             )\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprint_wrapper_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemExit\u001b[0m: 1","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}]},{"cell_type":"code","source":["!python -m onnxruntime.tools.make_dynamic_shape_fixed --input_name images --input_shape 1,3,640,640 /content/Notes/model_uint8_sparseml.onnx /content/Notes/model_uint8_sparseml.onnx"],"metadata":{"id":"qP7vZZiz32R_","executionInfo":{"status":"ok","timestamp":1711979309449,"user_tz":-420,"elapsed":3465,"user":{"displayName":"Việt Hoàng Trần","userId":"05840634668175400410"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","a = np.random.randint(0, high=255, size=(1, 3, 640, 640), dtype=np.uint8)\n","np.save(\"/content/Notes/data\", a)"],"metadata":{"id":"JEBZ7awXFPLC","executionInfo":{"status":"ok","timestamp":1711982225970,"user_tz":-420,"elapsed":2,"user":{"displayName":"Việt Hoàng Trần","userId":"05840634668175400410"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BYJCRn6Q6tcE"},"execution_count":null,"outputs":[]}]}